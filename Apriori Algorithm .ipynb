{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85ae711-5b58-4670-9d6a-7d48a7fd838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22af8b97-084a-4e45-9c70-4913deae37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    ['Coffee', 'Donut', 'Sandwich'],\n",
    "    ['Coffee', 'Donut'],\n",
    "    ['Coffee', 'Sandwich'],\n",
    "    ['Coffee', 'Muffin'],\n",
    "    ['Donut', 'Muffin']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a04ddb-518a-4e8d-92c5-816538388ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded dataframe:\n",
      "   Coffee  Donut  Muffin  Sandwich\n",
      "0    True   True   False      True\n",
      "1    True   True   False     False\n",
      "2    True  False   False      True\n",
      "3    True  False    True     False\n",
      "4   False   True    True     False\n"
     ]
    }
   ],
   "source": [
    "# Step 2: One-hot encoding\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(\"One-hot encoded dataframe:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f12240be-13f8-4560-8303-abb53fc7cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets (support >= 0.40):\n",
      "    support            itemsets\n",
      "0      0.8            (Coffee)\n",
      "1      0.6             (Donut)\n",
      "2      0.4            (Muffin)\n",
      "3      0.4          (Sandwich)\n",
      "4      0.4     (Coffee, Donut)\n",
      "5      0.4  (Coffee, Sandwich)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: find frequent itemsets\n",
    "min_support = 0.4\n",
    "freq_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# sort for neatness\n",
    "freq_itemsets = freq_itemsets.sort_values('support', ascending=False).reset_index(drop=True)\n",
    "print(\"Frequent itemsets (support >= {:.2f}):\\n\".format(min_support), freq_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49fefc41-7bf4-4206-becb-db4f34637a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rules derived from frequent itemsets:\n",
      "\n",
      "antecedents consequents  support  confidence     lift\n",
      "   Sandwich      Coffee      0.4    1.000000 1.250000\n",
      "      Donut      Coffee      0.4    0.666667 0.833333\n",
      "     Coffee       Donut      0.4    0.500000 0.833333\n",
      "     Coffee    Sandwich      0.4    0.500000 1.250000\n"
     ]
    }
   ],
   "source": [
    "# Step 4: generate all possible rules (no confidence filter)\n",
    "all_rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=0.0)\n",
    "\n",
    "# Keep only useful columns and format antecedent/consequent as strings for readability\n",
    "rules = all_rules[['antecedents','consequents','support','confidence','lift']].copy()\n",
    "rules['antecedents'] = rules['antecedents'].apply(lambda s: ', '.join(list(s)))\n",
    "rules['consequents'] = rules['consequents'].apply(lambda s: ', '.join(list(s)))\n",
    "\n",
    "# Sort by confidence for inspection\n",
    "rules = rules.sort_values('confidence', ascending=False).reset_index(drop=True)\n",
    "print(\"All rules derived from frequent itemsets:\\n\")\n",
    "print(rules.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23e29f62-2922-431b-954c-1a7744e8f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rules with support >= 0.40 and confidence >= 0.60:\n",
      "\n",
      "antecedents consequents  support  confidence     lift\n",
      "   Sandwich      Coffee      0.4    1.000000 1.250000\n",
      "      Donut      Coffee      0.4    0.666667 0.833333\n",
      "\n",
      "Pretty:\n",
      "Sandwich -> Coffee  (support=0.40, conf=1.00, lift=1.25)\n",
      "Donut -> Coffee  (support=0.40, conf=0.67, lift=0.83)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: filter rules by support & confidence thresholds\n",
    "min_support = 0.4   # same as used earlier (this is support of the whole rule i.e. union)\n",
    "min_confidence = 0.6\n",
    "\n",
    "filtered_rules = rules[(rules['support'] >= min_support) & (rules['confidence'] >= min_confidence)].copy()\n",
    "print(\"Rules with support >= {:.2f} and confidence >= {:.2f}:\\n\".format(min_support, min_confidence))\n",
    "if filtered_rules.empty:\n",
    "    print(\"No rules satisfy both thresholds.\")\n",
    "else:\n",
    "    print(filtered_rules.to_string(index=False))\n",
    "    # pretty print\n",
    "    print(\"\\nPretty:\")\n",
    "    for _, r in filtered_rules.iterrows():\n",
    "        print(f\"{r['antecedents']} -> {r['consequents']}  (support={r['support']:.2f}, conf={r['confidence']:.2f}, lift={r['lift']:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98aad32-1542-4dfe-a031-b4658f7e2aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strongest Rule Interpretation:\n",
      "If a customer buys S, a, n, d, w, i, c, h, they are likely to also buy C, o, f, f, e, e.\n",
      "(Confidence = 1.00, Lift = 1.25)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Interpret one strong rule in words\n",
    "if not filtered_rules.empty:\n",
    "    # choose the rule with max confidence\n",
    "    best_rule = filtered_rules.iloc[filtered_rules['confidence'].idxmax()]\n",
    "    antecedent = best_rule['antecedents']\n",
    "    consequent = best_rule['consequents']\n",
    "    conf = best_rule['confidence']\n",
    "    lift = best_rule['lift']\n",
    "    \n",
    "    print(\"Strongest Rule Interpretation:\")\n",
    "    print(f\"If a customer buys {', '.join(list(antecedent))}, they are likely to also buy {', '.join(list(consequent))}.\")\n",
    "    print(f\"(Confidence = {conf:.2f}, Lift = {lift:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d768f370-a8fa-4755-aa11-eea8efe87d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimenting with thresholds:\n",
      "min_support=0.2, min_confidence=0.4 -> 11 rules\n",
      "min_support=0.2, min_confidence=0.6 -> 3 rules\n",
      "min_support=0.2, min_confidence=0.8 -> 2 rules\n",
      "min_support=0.4, min_confidence=0.4 -> 4 rules\n",
      "min_support=0.4, min_confidence=0.6 -> 2 rules\n",
      "min_support=0.4, min_confidence=0.8 -> 1 rules\n",
      "min_support=0.6, min_confidence=0.4 -> 0 rules\n",
      "min_support=0.6, min_confidence=0.6 -> 0 rules\n",
      "min_support=0.6, min_confidence=0.8 -> 0 rules\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Experiment with min_support and min_confidence\n",
    "supports = [0.2, 0.4, 0.6]\n",
    "confidences = [0.4, 0.6, 0.8]\n",
    "\n",
    "print(\"Experimenting with thresholds:\")\n",
    "for s in supports:\n",
    "    freq_itemsets = apriori(df, min_support=s, use_colnames=True)\n",
    "    for c in confidences:\n",
    "        rules = association_rules(freq_itemsets, metric=\"confidence\", min_threshold=c)\n",
    "        print(f\"min_support={s}, min_confidence={c} -> {len(rules)} rules\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d44291f-e039-4871-9ede-5edc57605c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c0e15-01b3-4325-a25b-a7a741e56c08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
