{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abe4bfeb-7f08-4a3b-bd30-3bd29d37756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 6 iterations\n",
      "\n",
      "Value function (rows top->bottom):\n",
      "-4.10   -3.44   -2.71   -1.90   \n",
      "-3.44   -2.71   -1.90   -1.00   \n",
      "-2.71   -1.90   -1.00   0.00   \n",
      "-1.90   -1.00   0.00   0.00   \n",
      "\n",
      "Policy (T=terminal):\n",
      " v   v   v   v  \n",
      " v   v   v   v  \n",
      " v   v   v   v  \n",
      " >   >   >   T  \n"
     ]
    }
   ],
   "source": [
    "# Grid world and reinforcement learning parameters\n",
    "ROWS, COLS = 4, 4\n",
    "TERMINAL = (3, 3)  # terminal state (goal)\n",
    "\n",
    "ACTIONS = {\n",
    "    'U': (-1, 0),  # up\n",
    "    'D': (1, 0),   # down\n",
    "    'L': (0, -1),  # left\n",
    "    'R': (0, 1)    # right\n",
    "}\n",
    "\n",
    "GAMMA = 0.9  # discount factor\n",
    "THETA = 1e-4 # small threshold for convergence\n",
    "STEP_REWARD = -1  # reward for non-terminal steps\n",
    "TERMINAL_REWARD = 0 # reward at terminal\n",
    "\n",
    "# All states as (r, c) tuples\n",
    "states = [(r, c) for r in range(ROWS) for c in range(COLS)]\n",
    "\n",
    "def is_terminal(s):\n",
    "    \"\"\"Checks if a state is the terminal state.\"\"\"\n",
    "    return s == TERMINAL\n",
    "\n",
    "def next_state(s, action):\n",
    "    \"\"\"Deterministic transition with wall bounce (stay if would go off-grid).\"\"\"\n",
    "    if is_terminal(s):\n",
    "        return s\n",
    "\n",
    "    dr, dc = ACTIONS[action]\n",
    "    nr = max(0, min(ROWS - 1, s[0] + dr))\n",
    "    nc = max(0, min(COLS - 1, s[1] + dc))\n",
    "    return (nr, nc)\n",
    "\n",
    "def reward(s, s2):\n",
    "    \"\"\"Reward for moving from s to s2.\"\"\"\n",
    "    return TERMINAL_REWARD if is_terminal(s2) else STEP_REWARD\n",
    "\n",
    "# Initialize values to zero\n",
    "V = {s: 0.0 for s in states}\n",
    "\n",
    "# Value Iteration\n",
    "iteration = 0\n",
    "while True:\n",
    "    iteration += 1\n",
    "    delta = 0.0\n",
    "    newV = V.copy() # synchronous update\n",
    "\n",
    "    for s in states:\n",
    "        if is_terminal(s):\n",
    "            continue\n",
    "\n",
    "        # compute value for each action (deterministic => single next state)\n",
    "        action_values = []\n",
    "        for a in ACTIONS:\n",
    "            s2 = next_state(s, a)\n",
    "            r = reward(s, s2)\n",
    "            q = r + GAMMA * V[s2]\n",
    "            action_values.append(q)\n",
    "\n",
    "        best = max(action_values)\n",
    "        newV[s] = best\n",
    "        delta = max(delta, abs(V[s] - newV[s]))\n",
    "    \n",
    "    V = newV\n",
    "\n",
    "    if delta < THETA:\n",
    "        break\n",
    "\n",
    "# Extract greedy policy\n",
    "policy = {}\n",
    "arrow = {'U': '^', 'D': 'v', 'L': '<', 'R': '>'}\n",
    "\n",
    "for s in states:\n",
    "    if is_terminal(s):\n",
    "        policy[s] = 'T'\n",
    "        continue\n",
    "\n",
    "    best_a = None\n",
    "    best_q = float('-inf')\n",
    "\n",
    "    for a in ACTIONS:\n",
    "        s2 = next_state(s, a)\n",
    "        q = reward(s, s2) + GAMMA * V[s2]\n",
    "        if q > best_q:\n",
    "            best_q = q\n",
    "            best_a = a\n",
    "    \n",
    "    policy[s] = arrow[best_a]\n",
    "\n",
    "# Print values and policy in grid form\n",
    "print(\"Converged in\", iteration, \"iterations\\n\")\n",
    "print(\"Value function (rows top->bottom):\")\n",
    "for r in range(ROWS):\n",
    "    for c in range(COLS):\n",
    "        print(f\"{V[(r,c)]:.2f}\", end=\"   \")\n",
    "    print()\n",
    "\n",
    "print(\"\\nPolicy (T=terminal):\")\n",
    "for r in range(ROWS):\n",
    "    for c in range(COLS):\n",
    "        print(f\" {policy[(r,c)]} \", end=\" \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6dcce3-dcf1-450e-97ee-7f3cb62de065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
